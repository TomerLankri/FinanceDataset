{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:14:16.031558Z",
     "start_time": "2023-10-23T14:14:15.454105Z"
    }
   },
   "id": "212753846afe9c55"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "def remove_funny_tokens(text):\n",
    "    tokens = text.split()\n",
    "    sample = ' '.join(' '.join(tokens).replace('xe2x80x9c', ' ').replace('xe2x80x9d', ' ')\\\n",
    "                                      .replace('xe2x80x94', ' ').replace('xe2x80x99', \"'\")\\\n",
    "                                      .replace('xe2x80x98', \"'\").split())\n",
    "    return sample\n",
    "\n",
    "def clean_text(text):\n",
    "    cleaned_listed_text = []\n",
    "    listed_text = list(text)\n",
    "\n",
    "    for iter in range(len(listed_text) - 1):\n",
    "        if (listed_text[iter] == '\\\\' and listed_text[iter + 1] == 'n') or \\\n",
    "            (listed_text[iter] == 'n' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\' and listed_text[iter + 1] == 'r' or \\\n",
    "            (listed_text[iter] == 'r' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\' and listed_text[iter + 1] == 't' or \\\n",
    "            (listed_text[iter] == 't' and listed_text[iter - 1] == '\\\\'):\n",
    "            continue\n",
    "        elif listed_text[iter] == '\\\\':\n",
    "            continue\n",
    "        else:\n",
    "            cleaned_listed_text.append(listed_text[iter])\n",
    "\n",
    "    cleaned_text = ''.join([str(char) for char in cleaned_listed_text])\n",
    "    cleaned_text = remove_funny_tokens(cleaned_text)\n",
    "\n",
    "    return ''.join(cleaned_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-23T14:14:19.573010Z",
     "start_time": "2023-10-23T14:14:19.560307Z"
    }
   },
   "id": "44d75acdf6e7ea2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't acquire text for Ragged Dick with ID 20689. Link: http://www.gutenberg.org/ebooks/20689\n",
      "Couldn't save data for Ragged Dick with ID 20689. Link: http://www.gutenberg.org/ebooks/20689\n",
      "Couldn't acquire text for Freedom's Battle with ID 10366. Link: http://www.gutenberg.org/ebooks/10366\n",
      "Couldn't save data for Freedom's Battle with ID 10366. Link: http://www.gutenberg.org/ebooks/10366\n",
      "Couldn't acquire text for Sinking of the Titanic and Great Sea Disasters with ID 781. Link: http://www.gutenberg.org/ebooks/781\n",
      "Couldn't save data for Sinking of the Titanic and Great Sea Disasters with ID 781. Link: http://www.gutenberg.org/ebooks/781\n",
      "Couldn't acquire text for True Stories of History and Biography with ID 15697. Link: http://www.gutenberg.org/ebooks/15697\n",
      "Couldn't save data for True Stories of History and Biography with ID 15697. Link: http://www.gutenberg.org/ebooks/15697\n",
      "Couldn't acquire text for The Balkans: A History of Bulgaria—Serbia—Greece—Rumania—Turkey with ID 11716. Link: http://www.gutenberg.org/ebooks/11716\n",
      "Couldn't save data for The Balkans: A History of Bulgaria—Serbia—Greece—Rumania—Turkey with ID 11716. Link: http://www.gutenberg.org/ebooks/11716\n",
      "Couldn't acquire text for Manual of Egyptian Archaeology and Guide to the Study of Antiquities in Egypt with ID 14400. Link: http://www.gutenberg.org/ebooks/14400\n",
      "Couldn't save data for Manual of Egyptian Archaeology and Guide to the Study of Antiquities in Egypt with ID 14400. Link: http://www.gutenberg.org/ebooks/14400\n",
      "Couldn't acquire text for Early European History with ID 7960. Link: http://www.gutenberg.org/ebooks/7960\n",
      "Couldn't save data for Early European History with ID 7960. Link: http://www.gutenberg.org/ebooks/7960\n",
      "Couldn't acquire text for Dave Darrin's First Year at Annapolis with ID 12774. Link: http://www.gutenberg.org/ebooks/12774\n",
      "Couldn't save data for Dave Darrin's First Year at Annapolis with ID 12774. Link: http://www.gutenberg.org/ebooks/12774\n",
      "Couldn't acquire text for Five Little Peppers and How They Grew with ID 2770. Link: http://www.gutenberg.org/ebooks/2770\n",
      "Couldn't save data for Five Little Peppers and How They Grew with ID 2770. Link: http://www.gutenberg.org/ebooks/2770\n",
      "Couldn't acquire text for Elsie Dinsmore with ID 6440. Link: http://www.gutenberg.org/ebooks/6440\n",
      "Couldn't save data for Elsie Dinsmore with ID 6440. Link: http://www.gutenberg.org/ebooks/6440\n",
      "Couldn't acquire text for The Adventures of Danny Meadow Mouse with ID 25529. Link: http://www.gutenberg.org/ebooks/25529\n",
      "Couldn't save data for The Adventures of Danny Meadow Mouse with ID 25529. Link: http://www.gutenberg.org/ebooks/25529\n",
      "Couldn't acquire text for Tom Swift and His Motor-Cycle; Or, Fun and Adventures on the Road with ID 4230. Link: http://www.gutenberg.org/ebooks/4230\n",
      "Couldn't save data for Tom Swift and His Motor-Cycle; Or, Fun and Adventures on the Road with ID 4230. Link: http://www.gutenberg.org/ebooks/4230\n",
      "Couldn't acquire text for A Primary Reader: Old-time Stories, Fairy Tales and Myths Retold with ID 7841. Link: http://www.gutenberg.org/ebooks/7841\n",
      "Couldn't save data for A Primary Reader: Old-time Stories, Fairy Tales and Myths Retold with ID 7841. Link: http://www.gutenberg.org/ebooks/7841\n",
      "Couldn't acquire text for Fairy Tales Every Child Should Know with ID 14916. Link: http://www.gutenberg.org/ebooks/14916\n",
      "Couldn't save data for Fairy Tales Every Child Should Know with ID 14916. Link: http://www.gutenberg.org/ebooks/14916\n",
      "Couldn't acquire text for The Heroes; Or, Greek Fairy Tales for My Children with ID 677. Link: http://www.gutenberg.org/ebooks/677\n",
      "Couldn't save data for The Heroes; Or, Greek Fairy Tales for My Children with ID 677. Link: http://www.gutenberg.org/ebooks/677\n",
      "Couldn't acquire text for The Book of Nature Myths with ID 22420. Link: http://www.gutenberg.org/ebooks/22420\n",
      "Couldn't save data for The Book of Nature Myths with ID 22420. Link: http://www.gutenberg.org/ebooks/22420\n",
      "Couldn't acquire text for Folk Tales Every Child Should Know with ID 15164. Link: http://www.gutenberg.org/ebooks/15164\n",
      "Couldn't save data for Folk Tales Every Child Should Know with ID 15164. Link: http://www.gutenberg.org/ebooks/15164\n"
     ]
    }
   ],
   "source": [
    "df_metadata = pd.read_csv('gutenberg_metadata.csv')\n",
    "\n",
    "data = {'Author': None, 'Title': None, 'Link': None, 'ID': None, 'Bookshelf': None, 'Text': None}\n",
    "\n",
    "for key, row in df_metadata.iterrows():\n",
    "    if data['Author'] == None:\n",
    "        \n",
    "        data['Author'] = [row['Author']]\n",
    "    else:\n",
    "        data['Author'].append(row['Author'])\n",
    "\n",
    "    if data['Title'] == None:\n",
    "        data['Title'] = [row['Title']]\n",
    "    else:\n",
    "        data['Title'].append(row['Title'])\n",
    "\n",
    "    if data['Link'] == None:\n",
    "        data['Link'] = [row['Link']]\n",
    "    else:\n",
    "        data['Link'].append(row['Link'])\n",
    "\n",
    "    book_id = int(row['Link'].split('/')[-1])\n",
    "\n",
    "    if data['ID'] == None:\n",
    "        data['ID'] = [book_id]\n",
    "    else:\n",
    "        data['ID'].append(book_id)\n",
    "\n",
    "    if data['Bookshelf'] == None:\n",
    "        data['Bookshelf'] = [row['Bookshelf']]\n",
    "    else:\n",
    "        data['Bookshelf'].append(row['Bookshelf'])\n",
    "\n",
    "    text = np.nan\n",
    "    try:\n",
    "        text = strip_headers(load_etext(etextno=book_id,\n",
    "                                        mirror='http://www.mirrorservice.org/sites/ftp.ibiblio.org/pub/docs/books/gutenberg/')).strip()\n",
    "        text = ' '.join(' '.join(' '.join(text.split('\\n')).split('\\t')).split('\\r'))\n",
    "        text = ' '.join(text.split())\n",
    "        text = clean_text(str(text))\n",
    "    except:\n",
    "        try:\n",
    "            page = requests.get(row['Link'])\n",
    "            soup = BeautifulSoup(page.content, 'html.parser')\n",
    "            text_link = 'http://www.gutenberg.org' + soup.find_all(\"a\", string=\"Plain Text UTF-8\")[0]['href']\n",
    "            http_response_object = urlopen(text_link)\n",
    "\n",
    "            text = strip_headers(str(http_response_object.read()))\n",
    "            text = ' '.join(' '.join(' '.join(text.split('\\n')).split('\\t')).split('\\r'))\n",
    "            text = ' '.join(text.split())\n",
    "            text = clean_text(str(text))\n",
    "        except:\n",
    "            print(\"Couldn't acquire text for \" + row['Title'] + ' with ID ' + str(book_id) + '. Link: ' + row['Link'])\n",
    "\n",
    "    if data['Text'] == None:\n",
    "        data['Text'] = [' '.join(text.split(' '))]\n",
    "    else:\n",
    "        try:\n",
    "            data['Text'].append(' '.join(text.split(' ')))\n",
    "        except:\n",
    "            data['Text'].append(None)\n",
    "            print(\"Couldn't save data for \" + row['Title'] + ' with ID ' + str(book_id) + '. Link: ' + row['Link'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-10-23T14:06:07.507651Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_data = pd.DataFrame(data, columns = ['Title', 'Author', 'Link', 'ID', 'Bookshelf', 'Text'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97de05633e26f302"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(df_data))\n",
    "\n",
    "# Filtering finance-related books\n",
    "finance_keywords = ['finance', 'investment', 'stock market', 'economics', 'banking',\n",
    "                   'financial', 'trading', 'wealth', 'investing']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb8124d8ee8b5b18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mask = df_data['Text'].str.lower().str.contains('|'.join(finance_keywords), na=False) | \\\n",
    "       df_data['Title'].str.lower().str.contains('|'.join(finance_keywords), na=False)\n",
    "\n",
    "df_filtered = df_data[mask]\n",
    "\n",
    "print(len(df_data))\n",
    "\n",
    "# Save the filtered data\n",
    "df_filtered.to_csv('/gutenberg_finance_data.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78d4c26d5e2de56e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
